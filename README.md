# ğŸ¯ Face Recognition and Movement Tracking System
<div align="center" dir="auto">
<p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://cdn.haitrieu.com/wp-content/uploads/2021/10/Logo-DH-Dai-Nam-.png"><img src="https://cdn.haitrieu.com/wp-content/uploads/2021/10/Logo-DH-Dai-Nam-.png" alt="DaiNam University Logo" width="200" style="max-width: 100%;"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://scontent-hkg1-2.xx.fbcdn.net/v/t39.30808-6/480298007_122136352064573365_111720378361571091_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=6ee11a&_nc_ohc=v2OcMm1HlhMQ7kNvgFiUTAd&_nc_oc=AdjWORdAz7QIgLnTRh901TjdGOGtJ2FCnshrLadVeC3_RtP2MkehgTf1umYjP6-DHpo&_nc_zt=23&_nc_ht=scontent-hkg1-2.xx&_nc_gid=NUQDiuUEdU7AFBb-6HNdDw&oh=00_AYEzvSLFLSeqb32QWXuivh7zCNgfXELyDyat0hwF7d0FIw&oe=67DF3FC8"><img src="https://scontent-hkg1-2.xx.fbcdn.net/v/t39.30808-6/480298007_122136352064573365_111720378361571091_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=6ee11a&_nc_ohc=v2OcMm1HlhMQ7kNvgFiUTAd&_nc_oc=AdjWORdAz7QIgLnTRh901TjdGOGtJ2FCnshrLadVeC3_RtP2MkehgTf1umYjP6-DHpo&_nc_zt=23&_nc_ht=scontent-hkg1-2.xx&_nc_gid=NUQDiuUEdU7AFBb-6HNdDw&oh=00_AYEzvSLFLSeqb32QWXuivh7zCNgfXELyDyat0hwF7d0FIw&oe=67DF3FC8" alt="AIoTLab Logo" width="170" style="max-width: 100%;"></a>
</p>
<p dir="auto"><a href="https://fit.dainam.edu.vn" rel="nofollow"><img src="https://camo.githubusercontent.com/14375b31490acab17dd414aef749f3c109a82abaeae50592667c9955b79ce09a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d616465253230627925323041496f544c61622d626c75653f7374796c653d666f722d7468652d6261646765" alt="Made by AIoTLab" data-canonical-src="https://img.shields.io/badge/Made%20by%20AIoTLab-blue?style=for-the-badge" style="max-width: 100%;"></a>
<a href="https://fit.dainam.edu.vn" rel="nofollow"><img src="https://camo.githubusercontent.com/f33b9e36f6d7e3878c31898033ff8514d824d4f51d8cab187bf3eddc84e2a99e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f466163756c74792532306f66253230496e666f726d6174696f6e253230546563686e6f6c6f67792d677265656e3f7374796c653d666f722d7468652d6261646765" alt="Faculty of IT" data-canonical-src="https://img.shields.io/badge/Faculty%20of%20Information%20Technology-green?style=for-the-badge" style="max-width: 100%;"></a>
<a href="https://dainam.edu.vn" rel="nofollow"><img src="https://camo.githubusercontent.com/b503f479f429296dbff6eb7e1e583a962657044af1feb98e6dfc4a68a106a49e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4461694e616d253230556e69766572736974792d7265643f7374796c653d666f722d7468652d6261646765" alt="DaiNam University" data-canonical-src="https://img.shields.io/badge/DaiNam%20University-red?style=for-the-badge" style="max-width: 100%;"></a></p>
</div>
<div align="center">
  
[![Python](https://img.shields.io/badge/Python-3.6+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.0+-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0+-000000?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](LICENSE)

ğŸš€ An intelligent surveillance system using face recognition and motion detection to track user movement across 3 cameras, featuring real-time web interface and sound alerts.

</div>

## âœ¨ Highlighted Features

### ğŸ­ Face Recognition
- ğŸ§  Uses ResNet model for face feature extraction
- ğŸ‘¥ Supports multiple faces in single frame
- ğŸ¯ High accuracy with 0.5 matching threshold
- ğŸ“š Easy training with custom dataset

### ğŸ¬ Motion Detection
- ğŸ“¹ Uses MOG2 Background Subtraction algorithm
- ğŸ›ï¸ Customizable motion detection threshold
- ğŸ” Efficient noise and shadow handling

### ğŸ“¸ Multi-Camera Surveillance
- ğŸ¥ Camera A: Face recognition
- ğŸ“¹ Cameras B & C: Motion detection
- â±ï¸ Time synchronization between cameras

### ğŸ–¥ï¸ Web Interface
- ğŸ“º Live video streams from 3 cameras
- âš¡ Real-time status updates
- â²ï¸ Travel time display between points
- ğŸ Cycle completion notifications

### ğŸ”” Smart Alerts
- ğŸš¨ Sound alerts for exceeded travel time
- ğŸ”ˆ "Ting" notification for too fast movement
- ğŸ’¾ Movement data storage to MockAPI

## ğŸ› ï¸ System Requirements

### ğŸ’» Hardware
- 3ï¸âƒ£ IP cameras (RTSP/HTTP stream support)
- ğŸ“Š Recommended resolution: 160x120 pixels
- ğŸŒ Stable network connection

### ğŸ“¦ Software Dependencies
```bash
python>=3.6         # ğŸ Core runtime
face_recognition    # ğŸ‘¤ Face detection & recognition
opencv-python>=4.0  # ğŸ“¸ Image processing
flask>=2.0         # ğŸŒ Web framework
pygame             # ğŸ”Š Audio playback
numpy              # ğŸ”¢ Numerical operations
pillow            # ğŸ–¼ï¸ Image handling
requests          # ğŸŒ HTTP client
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Environment Setup
```bash
# ğŸ—ï¸ Create virtual environment
python -m venv venv

# ğŸŒŸ Activate virtual environment
source venv/bin/activate  # ğŸ§ Linux/Mac
venv\Scripts\activate     # ğŸªŸ Windows

# ğŸ“¦ Install dependencies
pip install -r requirements_dev.txt
```

### 2ï¸âƒ£ Camera Configuration
```python
# ğŸ¥ In demo.py
CAM_A_IP = 'http://192.168.1.101:4747/video'  # ğŸ‘¤ Face recognition
CAM_B_IP = 'http://192.168.1.102:4747/video'  # ğŸ“¹ Motion detection 1
CAM_C_IP = 'http://192.168.1.110:4747/video'  # ğŸ¥ Motion detection 2
```

### 3ï¸âƒ£ Dataset Preparation
```plaintext
ğŸ“ dataset/
 â”œâ”€â”€ ğŸ‘¤ person1.jpg        # Filename is label
 â”œâ”€â”€ ğŸ‘¥ person2-name.jpg   # Part after hyphen is label
 â””â”€â”€ ...
```

### 4ï¸âƒ£ Model Training
```bash
# ğŸ§  Train face recognition model
python face_recognition_train.py
```

## âš™ï¸ System Configuration

### ğŸ›ï¸ Key Parameters
```python
# â±ï¸ Travel times (seconds)
max_travel_time = 5    # â° Maximum between points
min_travel_time = 2    # âŒ› Minimum between points
min_valid_time = 0.5   # âœ… Minimum confirmation

# ğŸ‘¤ Face recognition
face_recognition_interval = 0.3  # ğŸ”„ Scan frequency
face_recognition_tolerance = 0.5 # ğŸ¯ Match threshold

# ğŸ“¹ Motion detection
motion_threshold = 1.5  # ğŸ“Š Pixel change percentage
```

### ğŸŒ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /` | ğŸ  Main web page |
| `GET /video_feed_[a\|b\|c]` | ğŸ“¹ Camera streams |
| `GET /face_status` | ğŸ‘¤ Recognition status |
| `GET /current_time` | â±ï¸ Cycle time |
| `GET /travel_time` | ğŸ•’ Travel times |
| `GET /completion_status` | âœ… Cycle status |

## ğŸ”„ Operation Process

### 1ï¸âƒ£ System Startup
- ğŸ¥ Initialize cameras
- ğŸ§  Load face model
- ğŸŒ Start web server

### 2ï¸âƒ£ Surveillance Cycle
- ğŸ‘¤ Face verification
- â±ï¸ Time counting
- ğŸ“¹ Motion detection
- âœ… Return confirmation

### 3ï¸âƒ£ Data Recording
```json
{
    "start_time": "2025-03-18T18:56:44",
    "end_time": "2025-03-18T18:57:11",
    "travel_time_a_b": 3.5,
    "travel_time_b_c": 4.2,
    "travel_time_c_a": 3.8
}
```

## ğŸ“œ License

See the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. ğŸ´ Fork repository
2. ğŸŒŸ Create feature branch
3. âœï¸ Commit changes
4. ğŸ“¤ Push to branch
5. ğŸ“« Create Pull Request

## ğŸ”’ Safety Notes

- ğŸ¢ Place cameras securely
- ğŸŒ Check network regularly
- ğŸ’¾ Backup data periodically
- ğŸ”‘ Update security settings

---
<div align="center">
  
Made with â¤ï¸ for security and efficiency

[â¬† Back to top](#-face-recognition-and-movement-tracking-system)

</div>
